name: External A-Z Link Checker

on:
  schedule:
    - cron: '0 0 * * 0'  # Run weekly on Sundays at midnight UTC
  workflow_dispatch:  # Allow manual triggering

permissions:
    contents: write  # Add explicit permission to write to repository  

jobs:
  linkchecker:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}  # Use Github token for authentication

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'

    - name: Cache pip packages
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        pip install requests beautifulsoup4 aiohttp

    - name: Run Link Checker
      run: |
        cat << EOF > check_links.py
        import csv
        import asyncio
        import aiohttp
        from bs4 import BeautifulSoup
        from datetime import datetime
        import os
        import sys
        from urllib.parse import urlparse, urljoin

        async def check_link(session, url):
            try:
                async with session.get(url, timeout=10) as response:
                    return url, response.status, response.headers.get('content-type', '')
            except Exception as e:
                return url, 'Error', str(e)

        async def check_links(start_url):
            base_domain = 'soton.ac.uk'
            visited = set()
            to_visit = [start_url]
            results = []

            async with aiohttp.ClientSession() as session:
                while to_visit:
                    url = to_visit.pop(0)
                    if url in visited:
                        continue
                    visited.add(url)

                    parsed_url = urlparse(url)
                    if base_domain in parsed_url.netloc:
                        # Only parse HTML for internal links
                        try:
                            async with session.get(url, timeout=10) as response:
                                text = await response.text()
                            soup = BeautifulSoup(text, 'html.parser')
                            for link in soup.find_all('a', href=True):
                                new_url = urljoin(url, link['href'])
                                new_parsed_url = urlparse(new_url)
                                if base_domain not in new_parsed_url.netloc and new_parsed_url.scheme in ['http', 'https']:
                                    if new_url not in visited:
                                        to_visit.append(new_url)
                        except Exception as e:
                            print(f"Error parsing {url}: {str(e)}", file=sys.stderr)
                    else:
                        # Check external links
                        url, status_code, content_type = await check_link(session, url)
                        results.append((url, status_code, content_type))
                        print(f"Checked: {url} - Status: {status_code} - Content-Type: {content_type}")

            return results

        async def main():
            start_url = "${{ secrets.AZ_URL }}"
            results = await check_links(start_url)

            os.makedirs('reports', exist_ok=True)
            date = datetime.now().strftime('%Y-%m-%d')
            report_file = f"reports/lib-AZ-external-links-report-{date}.csv"

            with open(report_file, 'w', newline='') as csvfile:
                writer = csv.writer(csvfile)
                writer.writerow(['URL', 'Status Code', 'Content-Type'])
                for url, status_code, content_type in results:
                    writer.writerow([url, status_code, content_type])

            print(f"REPORT_FILE={report_file}")
            with open(os.environ['GITHUB_ENV'], 'a') as env_file:
                env_file.write(f"REPORT_FILE={report_file}\n")

            broken_links = [url for url, status, _ in results if status != 200]
            if broken_links:
                print("broken_links_found=true")
                print("STATUS_MESSAGE=Broken external links have been detected on the Library A-Z. Please check attached report for all link details.")
                with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                    f.write("broken_links_found=true\n")
                with open(os.environ['GITHUB_ENV'], 'a') as f:
                    f.write("STATUS_MESSAGE=Broken external links have been detected on the Library A-Z. Please check attached report for all link details.\n")
            else:
                print("broken_links_found=false")
                print("STATUS_MESSAGE=No broken external links found. Please check attached report for all link details.")
                with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                    f.write("broken_links_found=false\n")
                with open(os.environ['GITHUB_ENV'], 'a') as f:
                    f.write("STATUS_MESSAGE=No broken external links found. Please check attached report for all link details.\n")

        if __name__ == "__main__":
            asyncio.run(main())
        EOF

        python check_links.py

    # Commit the report to the repository
    - name: Commit report to repository
      if: always()
      run: |
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        git add "${{ env.REPORT_FILE }}"
        if git diff --staged --quiet; then
          echo "No changes to commit"
        else
          git commit -m "Add links report for $(date +'%Y-%m-%d')"
          git push origin HEAD:${GITHUB_REF}
        fi
  
    # Upload the report as an artifact
    - name: Upload links report
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: links-report
        path: ${{ env.REPORT_FILE }}
    
    # Send email notification with the report
    - name: Send email notification
      id: send_email
      if: always()
      uses: dawidd6/action-send-mail@v3
      with:
        server_address: smtp.gmail.com
        server_port: 465
        username: ${{secrets.GMAIL_USERNAME}}
        password: ${{secrets.GMAIL_PASSWORD}}
        subject: ${{ steps.check_broken_links.outputs.broken_links_found == 'true' && 'Broken Links Found on Library A-Z website' || 'No Broken Links Found on Library A-Z website' }}
        body: ${{ env.STATUS_MESSAGE }}
        attachments: ${{ env.REPORT_FILE }}
        to: ${{secrets.EMAIL_RECIPIENT}}
        from: Alistair Bailey ${{secrets.EMAIL_SENDER}}
        priority: normal
        secure: true
      env:
        STATUS_MESSAGE: ${{ env.STATUS_MESSAGE }}
